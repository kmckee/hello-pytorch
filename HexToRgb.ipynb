{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hex to RGB\n",
    "\n",
    "Can I train a neural network to convert hex color codes to RGB?  \n",
    "\n",
    "## Generate some sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hex_to_rgb(hex):\n",
    "  hex = hex.replace('#', '')\n",
    "  rgb = []\n",
    "  for i in (0, 2, 4):\n",
    "    decimal = int(hex[i:i+2], 16)\n",
    "    rgb.append(decimal)\n",
    "  \n",
    "  return tuple(rgb)\n",
    "\n",
    "hex_to_rgb('FFA502')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#F5AEBB\n",
      "(245, 174, 187)\n"
     ]
    }
   ],
   "source": [
    "def random_hex_color(): \n",
    "\tr = lambda: random.randint(0,255)\n",
    "\treturn '#%02X%02X%02X' % (r(),r(),r())\n",
    "\n",
    "randomColor = random_hex_color()\n",
    "print(randomColor)\n",
    "asRgb = hex_to_rgb(randomColor)\n",
    "print(asRgb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate some training data\n",
    "\n",
    "Create random colors, convert them between types, and output everything into a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_colors = 20000\n",
    "colors = [random_hex_color() for _ in range(num_colors)]\n",
    "rgb_values = [hex_to_rgb(color) for color in colors]\n",
    "\n",
    "data = {'Hex': colors, 'R': [rgb[0] for rgb in rgb_values], 'G': [rgb[1] for rgb in rgb_values], 'B': [rgb[2] for rgb in rgb_values]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv('rgb_colors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative data generation\n",
    "\n",
    "Shamelessly stolen from chatgpt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_hex(rgb):\n",
    "    return ''.join([format(val, '02X') for val in rgb])\n",
    "\n",
    "def hex_to_rgb(hex_str):\n",
    "    return tuple(int(hex_str[i:i+2], 16) for i in range(0, 6, 2))\n",
    "\n",
    "def generate_data(num_samples=1000):\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        rgb = [random.randint(0, 255) for _ in range(3)]\n",
    "        hex_str = rgb_to_hex(rgb)\n",
    "        data.append((rgb, hex_str))\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we go..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the network architecture\n",
    "class ColorPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorPredictor, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.output_layers = nn.ModuleList([nn.Linear(128, 4) for _ in range(6)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return [output_layer(x) for output_layer in self.output_layers]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, num_epochs=100, learning_rate=1e-3):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        random.shuffle(data)\n",
    "\n",
    "        for rgb, hex_str in data:\n",
    "            input_tensor = torch.tensor(rgb, dtype=torch.float32) / 255.0\n",
    "            target_tensors = [torch.tensor(list(map(int, format(int(char, 16), '04b'))), dtype=torch.float32) for char in hex_str]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(input_tensor)\n",
    "            loss = sum([criterion(output, target_tensor) for output, target_tensor in zip(outputs, target_tensors)])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 3.8403032214641573\n",
      "Epoch 2/100, Loss: 3.6680932943820954\n",
      "Epoch 3/100, Loss: 3.6342421395778657\n",
      "Epoch 4/100, Loss: 3.5949534103870393\n",
      "Epoch 5/100, Loss: 3.5341393692493437\n",
      "Epoch 6/100, Loss: 3.473819903612137\n",
      "Epoch 7/100, Loss: 3.410453906536102\n",
      "Epoch 8/100, Loss: 3.3516240005493163\n",
      "Epoch 9/100, Loss: 3.3148777453899383\n",
      "Epoch 10/100, Loss: 3.284304325580597\n",
      "Epoch 11/100, Loss: 3.2571546547412873\n",
      "Epoch 12/100, Loss: 3.2400084664821627\n",
      "Epoch 13/100, Loss: 3.2231007726192473\n",
      "Epoch 14/100, Loss: 3.210009129047394\n",
      "Epoch 15/100, Loss: 3.1924591579437256\n",
      "Epoch 16/100, Loss: 3.1767403061389925\n",
      "Epoch 17/100, Loss: 3.1680440282821656\n",
      "Epoch 18/100, Loss: 3.157997973918915\n",
      "Epoch 19/100, Loss: 3.1466429386138914\n",
      "Epoch 20/100, Loss: 3.139504885196686\n",
      "Epoch 21/100, Loss: 3.1244098286628725\n",
      "Epoch 22/100, Loss: 3.120645533323288\n",
      "Epoch 23/100, Loss: 3.1102321968078614\n",
      "Epoch 24/100, Loss: 3.0990334696769715\n",
      "Epoch 25/100, Loss: 3.100455060958862\n",
      "Epoch 26/100, Loss: 3.0863240424394607\n",
      "Epoch 27/100, Loss: 3.085772761106491\n",
      "Epoch 28/100, Loss: 3.082273838043213\n",
      "Epoch 29/100, Loss: 3.073517107963562\n",
      "Epoch 30/100, Loss: 3.071038478374481\n",
      "Epoch 31/100, Loss: 3.0633519201278685\n",
      "Epoch 32/100, Loss: 3.062596304178238\n",
      "Epoch 33/100, Loss: 3.055194655418396\n",
      "Epoch 34/100, Loss: 3.052197673559189\n",
      "Epoch 35/100, Loss: 3.0396881856918334\n",
      "Epoch 36/100, Loss: 3.0315891573429106\n",
      "Epoch 37/100, Loss: 3.0236831250190734\n",
      "Epoch 38/100, Loss: 3.0238967337608336\n",
      "Epoch 39/100, Loss: 3.0226777052879332\n",
      "Epoch 40/100, Loss: 3.0126256127357482\n",
      "Epoch 41/100, Loss: 3.0051891145706175\n",
      "Epoch 42/100, Loss: 3.0088922636508943\n",
      "Epoch 43/100, Loss: 2.989528020143509\n",
      "Epoch 44/100, Loss: 2.989885655283928\n",
      "Epoch 45/100, Loss: 2.987087623119354\n",
      "Epoch 46/100, Loss: 2.985534345149994\n",
      "Epoch 47/100, Loss: 2.9751244342327117\n",
      "Epoch 48/100, Loss: 2.973700995922089\n",
      "Epoch 49/100, Loss: 2.9702452763319016\n",
      "Epoch 50/100, Loss: 2.9699195783138275\n",
      "Epoch 51/100, Loss: 2.957923790574074\n",
      "Epoch 52/100, Loss: 2.976303651571274\n",
      "Epoch 53/100, Loss: 2.9593376381397247\n",
      "Epoch 54/100, Loss: 2.9537114813327787\n",
      "Epoch 55/100, Loss: 2.955156783461571\n",
      "Epoch 56/100, Loss: 2.9512830572128297\n",
      "Epoch 57/100, Loss: 2.955111258149147\n",
      "Epoch 58/100, Loss: 2.9421910738945005\n",
      "Epoch 59/100, Loss: 2.9470228434801102\n",
      "Epoch 60/100, Loss: 2.9310252239704133\n",
      "Epoch 61/100, Loss: 2.9459304461479188\n",
      "Epoch 62/100, Loss: 2.9329227954149246\n",
      "Epoch 63/100, Loss: 2.9189389317035674\n",
      "Epoch 64/100, Loss: 2.9271771594285965\n",
      "Epoch 65/100, Loss: 2.9289038145542143\n",
      "Epoch 66/100, Loss: 2.9161392161846162\n",
      "Epoch 67/100, Loss: 2.91911791908741\n",
      "Epoch 68/100, Loss: 2.92118071103096\n",
      "Epoch 69/100, Loss: 2.911867438793182\n",
      "Epoch 70/100, Loss: 2.897461964607239\n",
      "Epoch 71/100, Loss: 2.9075945327281953\n",
      "Epoch 72/100, Loss: 2.9031747623682023\n",
      "Epoch 73/100, Loss: 2.903488548398018\n",
      "Epoch 74/100, Loss: 2.8903793880939483\n",
      "Epoch 75/100, Loss: 2.892026817679405\n",
      "Epoch 76/100, Loss: 2.8844535447359085\n",
      "Epoch 77/100, Loss: 2.8889062606096267\n",
      "Epoch 78/100, Loss: 2.8773349828720094\n",
      "Epoch 79/100, Loss: 2.8788527163267137\n",
      "Epoch 80/100, Loss: 2.876960499882698\n",
      "Epoch 81/100, Loss: 2.866812434196472\n",
      "Epoch 82/100, Loss: 2.869435615181923\n",
      "Epoch 83/100, Loss: 2.866743671774864\n",
      "Epoch 84/100, Loss: 2.86348393535614\n",
      "Epoch 85/100, Loss: 2.8514146069288255\n",
      "Epoch 86/100, Loss: 2.847256115913391\n",
      "Epoch 87/100, Loss: 2.847006925702095\n",
      "Epoch 88/100, Loss: 2.8544874402284623\n",
      "Epoch 89/100, Loss: 2.840802820086479\n",
      "Epoch 90/100, Loss: 2.8484468991756438\n",
      "Epoch 91/100, Loss: 2.839466274857521\n",
      "Epoch 92/100, Loss: 2.829248220562935\n",
      "Epoch 93/100, Loss: 2.842994857430458\n",
      "Epoch 94/100, Loss: 2.82486669588089\n",
      "Epoch 95/100, Loss: 2.8226228501796724\n",
      "Epoch 96/100, Loss: 2.819991532206535\n",
      "Epoch 97/100, Loss: 2.827057710647583\n",
      "Epoch 98/100, Loss: 2.820143499970436\n",
      "Epoch 99/100, Loss: 2.814181431889534\n",
      "Epoch 100/100, Loss: 2.8157306287288666\n"
     ]
    }
   ],
   "source": [
    "model = ColorPredictor()\n",
    "data = generate_data()\n",
    "train(model, data)\n",
    "torch.save(model.state_dict(), 'color_predictor.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
